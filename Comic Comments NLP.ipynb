{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping and analyzing reviews on comics for readcomiconline.to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERAL\n",
    "import re\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# WEBSCRAPING\n",
    "import requests\n",
    "import bs4 as bs\n",
    "\n",
    "# SELENIUM\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "# NLP\n",
    "import spacy\n",
    "from textblob import TextBlob\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# GRAPHICS\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD NLP MODEL\n",
    "# nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Webscrape results, export to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.0 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comment_soup(driver, url):\n",
    "    \"\"\"\n",
    "    For a given url, uses Selenium to get the \"src\" link to the Disqus comments page.\n",
    "    Returns bs4 soup file for Disqus comments page.\n",
    "    \"\"\"\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(5) # Wait to load\n",
    "    \n",
    "    iframe = driver.find_element_by_xpath(\"//iframe[2]\") # Disqus comments are in XPATH //inframe[2]\"\n",
    "    iframe_url = iframe.get_attribute('src') # \"src\" is link to Disqus comments\n",
    "    driver.close() # close webpage\n",
    "    # Instantiate BS, create soup for Disqus url\n",
    "    source_code = requests.get(iframe_url)\n",
    "    plain_text = source_code.text\n",
    "    soup = bs.BeautifulSoup(plain_text, 'html.parser')\n",
    "    \n",
    "    return soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET COMMENTS FROM SOUP FILE\n",
    "def soup_to_json(soup):\n",
    "    \"\"\"\n",
    "    Returns json-formatted messages of bs4 soup file\n",
    "    Returns json_data, a list of dicts\n",
    "    \"\"\"\n",
    "    json_data_str = str(soup.find(\"script\", {\"id\" : \"disqus-threadData\"})) # string of json_data\n",
    "    json_data_str2 = json_data_str[json_data_str.find('json')+6:-9] # remove head/foot tags\n",
    "    json_data = json.loads(json_data_str2) # string to json\n",
    "    json_data = json_data['response']['posts']\n",
    "    \n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_messages(df, url, json_data):\n",
    "    \"\"\"\n",
    "    Takes in a df of form ['Webpage','Message', 'Author', 'Likes', 'Dislikes', 'NumReports']\n",
    "    Appends each message and metadata (50 max) to that df.\n",
    "    Returns the updated df\n",
    "    \"\"\"\n",
    "    if \"?\" in url:\n",
    "        webpage = url[33:url.find('?id')] # set webpage (comic title/issue)\n",
    "    else:\n",
    "        webpage = url[33:]\n",
    "        \n",
    "    # Check all messages (50 max) per webpage\n",
    "    for i in range(len(json_data)):\n",
    "#         print(json_data[i])\n",
    "\n",
    "        message = json_data[i]['message'] # MESSAGE\n",
    "        message = re.compile(r'<[^>]+>').sub('', message) # remove all html tags\n",
    "        try:\n",
    "            author = json_data[i]['author']['username'] # if the author has a username\n",
    "        except:\n",
    "            author = json_data[i]['author']['name'] # if the author is a guest\n",
    "        likes = json_data[i]['likes']\n",
    "        dislikes = json_data[i]['dislikes']\n",
    "        numReports = json_data[i]['numReports']\n",
    "\n",
    "        data=[webpage, message, author, likes, dislikes, numReports]\n",
    "        append_me = pd.Series(data=data, index = df.columns)\n",
    "        df = df.append(append_me, ignore_index=True) # Append the new Series into df\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.1 Webscrape comments for one issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_issue(url, df=None):\n",
    "    \"\"\"\n",
    "    Scrapes issue for a single url (e.g. \"https://readcomiconline.to/Comic/The-Wild-Storm/Issue-4\")\n",
    "    Can be passed a df with some issues already scraped\n",
    "    Returns a df with comments for single scraped issue\n",
    "    \"\"\"\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(columns=['Webpage','Message', 'Author', 'Likes', 'Dislikes', 'NumReports'])\n",
    "        print(\"new df created\")\n",
    "\n",
    "    else:\n",
    "        print(\"df loaded\")\n",
    "\n",
    "    driver = webdriver.Opera(executable_path='/Users/abgrss/Documents/Projects/Brain Station/00 Capstone project/operadriver_mac64/operadriver')\n",
    "\n",
    "    if url[33:] not in df['Webpage'].values: # If the webpage hasn't yet been scraped\n",
    "        # RUN ALL FUNCTIONS\n",
    "        try:\n",
    "            print(f\"Now scraping: {url[33:]}\")\n",
    "            soup = get_comment_soup(driver, url)\n",
    "            json_data = soup_to_json(soup)\n",
    "            df = get_messages(df, url, json_data)\n",
    "            df.to_csv('comic_comments/comic_comments.csv') # SAVE AFTER EVERY SUCCESSFUL ISSUE SCRAPE\n",
    "        # IF WEBSCRAPING FAILS\n",
    "        except:\n",
    "            print(f\"SCRAPING FAILED for {url}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.1.1 Single Issue: \"The Wild Storm\", Issue 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new df created\n",
      "Now scraping: The-Wild-Storm/Issue-4\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "      <th>Message</th>\n",
       "      <th>Author</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>NumReports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>This is great writing. I don't like all the ch...</td>\n",
       "      <td>matejsojka</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td></td>\n",
       "      <td>Guest</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>shame it's not yet confirmed to be part of the...</td>\n",
       "      <td>kareematta</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td></td>\n",
       "      <td>Guest</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>Some of the best art in comics right now, I ge...</td>\n",
       "      <td>disqus_2fQDYhg09f</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>Oh, the plot thickens. But the game is not afo...</td>\n",
       "      <td>MotherOfCreation</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>cant wait for next issue. hoping for more acti...</td>\n",
       "      <td>NANANANANANAN_batman</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>Just realized Kenesha (Savant) is now black. S...</td>\n",
       "      <td>vadimfv</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>It's more interesting this way.  Things get to...</td>\n",
       "      <td>jasonhughnon</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>I agree with what stan lee said regarding this...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td></td>\n",
       "      <td>Guest</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>He literally wrote sparks dood lol sparks was ...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>I've read all the issues so far and am pretty ...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>WOW... just wow.  I can't get enough of this. ...</td>\n",
       "      <td>disqus_IXFawpGLcU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Webpage                                            Message  \\\n",
       "0   The-Wild-Storm/Issue-4  This is great writing. I don't like all the ch...   \n",
       "1   The-Wild-Storm/Issue-4                                                      \n",
       "2   The-Wild-Storm/Issue-4  shame it's not yet confirmed to be part of the...   \n",
       "3   The-Wild-Storm/Issue-4                                                      \n",
       "4   The-Wild-Storm/Issue-4  Some of the best art in comics right now, I ge...   \n",
       "5   The-Wild-Storm/Issue-4  Oh, the plot thickens. But the game is not afo...   \n",
       "6   The-Wild-Storm/Issue-4  cant wait for next issue. hoping for more acti...   \n",
       "7   The-Wild-Storm/Issue-4  Just realized Kenesha (Savant) is now black. S...   \n",
       "8   The-Wild-Storm/Issue-4  It's more interesting this way.  Things get to...   \n",
       "9   The-Wild-Storm/Issue-4  I agree with what stan lee said regarding this...   \n",
       "10  The-Wild-Storm/Issue-4                                                      \n",
       "11  The-Wild-Storm/Issue-4  He literally wrote sparks dood lol sparks was ...   \n",
       "12  The-Wild-Storm/Issue-4  I've read all the issues so far and am pretty ...   \n",
       "13  The-Wild-Storm/Issue-4  WOW... just wow.  I can't get enough of this. ...   \n",
       "\n",
       "                  Author Likes Dislikes NumReports  \n",
       "0             matejsojka     6        0          0  \n",
       "1                  Guest     5        0          0  \n",
       "2             kareematta     0        0          0  \n",
       "3                  Guest     3        0          0  \n",
       "4      disqus_2fQDYhg09f     2        0          0  \n",
       "5       MotherOfCreation     1        0          0  \n",
       "6   NANANANANANAN_batman     1        0          0  \n",
       "7                vadimfv     3        4          0  \n",
       "8           jasonhughnon     5        2          0  \n",
       "9         LEGENDOFLEGAIA     1        0          0  \n",
       "10                 Guest     2        0          0  \n",
       "11        LEGENDOFLEGAIA     0        1          0  \n",
       "12        LEGENDOFLEGAIA     0        0          0  \n",
       "13     disqus_IXFawpGLcU     0        0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SAMPLE SINGLE-ISSUE SCRAPING\n",
    "url = \"https://readcomiconline.to/Comic/The-Wild-Storm/Issue-4\"\n",
    "df_wild_issue = scrape_issue(url)\n",
    "df_wild_issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0.2 Webscrape comic series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scrape_series(series_title, series_length, start_issue=1, df=None, prev_fails=0):\n",
    "    \"\"\"\n",
    "    Takes in a a root page directory (e.g. https://readcomiconline.to/Comic/The-Wild-Storm/)\n",
    "    Can be passed a df with some issues already scraped\n",
    "    Returns a df with comments for scraped issues\n",
    "    \"\"\"\n",
    "    fails = 0\n",
    "    # INITIATE DF\n",
    "    if df is None:\n",
    "        df = pd.DataFrame(columns=['Webpage','Message', 'Author', 'Likes', 'Dislikes', 'NumReports'])\n",
    "        print(\"new df created\")\n",
    "\n",
    "    else:\n",
    "        print(\"df loaded\")\n",
    "\n",
    "    ### ADD CODE: GET LENGTH FROM PAGE ###\n",
    "    \n",
    "    # FOR EVERY ISSUE\n",
    "    for i in range(start_issue,series_length+1):\n",
    "        url = series_title+\"Issue-\"+str(i)\n",
    "        if url[33:] not in df['Webpage'].values: # If the webpage hasn't yet been scraped\n",
    "        \n",
    "            # RUN ALL WEBSCRAPING FUNCTIONS\n",
    "            driver = webdriver.Opera(executable_path='/Users/abgrss/Documents/Projects/Brain Station/00 Capstone project/operadriver_mac64/operadriver')\n",
    "            try:\n",
    "                print(f\"Now scraping: {url[33:]}\")\n",
    "                soup = get_comment_soup(driver, url)\n",
    "                json_data = soup_to_json(soup)\n",
    "                df = get_messages(df, url, json_data)\n",
    "                df.to_csv('comic_comments/comic_comments.csv') # SAVE AFTER EVERY SUCCESSFUL ISSUE SCRAPE\n",
    "            # IF WEBSCRAPING FAILS\n",
    "            except:\n",
    "                print(f\"SCRAPING FAILED for {url}\")\n",
    "                fails = fails + 1\n",
    "                continue\n",
    "    # IF ANY SCRAPING FAILS\n",
    "    if fails > 0:\n",
    "        if fails != prev_fails: #IF FAILS NOT THE SAME AS BEFORE, RUNS FUNCTION RECURSIVELY\n",
    "            df = scrape_series(series_title, series_length, start_issue=1, df=df, prev_fails=fails)\n",
    "        else:\n",
    "            print(f\"TOTAL SCRAPE FAILS: {fails}\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.1 \"Justice League\" 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new df created\n",
      "Now scraping: Justice-League-2018/Issue-1\n",
      "Now scraping: Justice-League-2018/Issue-2\n",
      "Now scraping: Justice-League-2018/Issue-3\n",
      "Now scraping: Justice-League-2018/Issue-4\n",
      "Now scraping: Justice-League-2018/Issue-5\n",
      "Now scraping: Justice-League-2018/Issue-6\n",
      "Now scraping: Justice-League-2018/Issue-7\n",
      "Now scraping: Justice-League-2018/Issue-8\n",
      "Now scraping: Justice-League-2018/Issue-9\n",
      "Now scraping: Justice-League-2018/Issue-10\n",
      "Now scraping: Justice-League-2018/Issue-11\n",
      "Now scraping: Justice-League-2018/Issue-12\n",
      "SCRAPING FAILED for https://readcomiconline.to/Comic/Justice-League-2018/Issue-12\n",
      "Now scraping: Justice-League-2018/Issue-13\n",
      "Now scraping: Justice-League-2018/Issue-14\n",
      "Now scraping: Justice-League-2018/Issue-15\n",
      "Now scraping: Justice-League-2018/Issue-16\n",
      "Now scraping: Justice-League-2018/Issue-17\n",
      "Now scraping: Justice-League-2018/Issue-18\n",
      "Now scraping: Justice-League-2018/Issue-19\n",
      "Now scraping: Justice-League-2018/Issue-20\n",
      "Now scraping: Justice-League-2018/Issue-21\n",
      "Now scraping: Justice-League-2018/Issue-22\n",
      "Now scraping: Justice-League-2018/Issue-23\n",
      "df loaded\n",
      "Now scraping: Justice-League-2018/Issue-12\n"
     ]
    }
   ],
   "source": [
    "# SCRAPE SERIES (JUSTICE LEAUGE 2018)\n",
    "series_length=23\n",
    "series_title = \"https://readcomiconline.to/Comic/Justice-League-2018/\"\n",
    "df_justice = scrape_series(series_title, series_length)\n",
    "df_justice.to_csv('comic_comments/justice_league_2018_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "      <th>Message</th>\n",
       "      <th>Author</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>NumReports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>Justice-League-2018/Issue-12</td>\n",
       "      <td>i personally love how Poseidon was written, ve...</td>\n",
       "      <td>disqus_L3EKnoSckT</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>Justice-League-2018/Issue-12</td>\n",
       "      <td>Another Jason Momoa cover as Aquaman. I like h...</td>\n",
       "      <td>matejsojka</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>Justice-League-2018/Issue-12</td>\n",
       "      <td>Loved the art in this</td>\n",
       "      <td>MrRootbeer94</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1140</th>\n",
       "      <td>Justice-League-2018/Issue-12</td>\n",
       "      <td>BTW how did Manta and/or the Triumvirate knew ...</td>\n",
       "      <td>disqus_rtgXlikKh3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>Justice-League-2018/Issue-12</td>\n",
       "      <td>Luthor told Manta most likely, seeing as hes t...</td>\n",
       "      <td>abrahamgeoffdusk</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Webpage  \\\n",
       "1137  Justice-League-2018/Issue-12   \n",
       "1138  Justice-League-2018/Issue-12   \n",
       "1139  Justice-League-2018/Issue-12   \n",
       "1140  Justice-League-2018/Issue-12   \n",
       "1141  Justice-League-2018/Issue-12   \n",
       "\n",
       "                                                Message             Author  \\\n",
       "1137  i personally love how Poseidon was written, ve...  disqus_L3EKnoSckT   \n",
       "1138  Another Jason Momoa cover as Aquaman. I like h...         matejsojka   \n",
       "1139                              Loved the art in this       MrRootbeer94   \n",
       "1140  BTW how did Manta and/or the Triumvirate knew ...  disqus_rtgXlikKh3   \n",
       "1141  Luthor told Manta most likely, seeing as hes t...   abrahamgeoffdusk   \n",
       "\n",
       "     Likes Dislikes NumReports  \n",
       "1137     0        0          0  \n",
       "1138     0        0          0  \n",
       "1139     0        0          0  \n",
       "1140     0        0          0  \n",
       "1141     0        0          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_justice.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.2 \"The Wild Storm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new df created\n",
      "Now scraping: The-Wild-Storm/Issue-1\n",
      "Now scraping: The-Wild-Storm/Issue-2\n",
      "Now scraping: The-Wild-Storm/Issue-3\n",
      "Now scraping: The-Wild-Storm/Issue-4\n",
      "SCRAPING FAILED for https://readcomiconline.to/Comic/The-Wild-Storm/Issue-4\n",
      "Now scraping: The-Wild-Storm/Issue-5\n",
      "Now scraping: The-Wild-Storm/Issue-6\n",
      "Now scraping: The-Wild-Storm/Issue-7\n",
      "Now scraping: The-Wild-Storm/Issue-8\n",
      "Now scraping: The-Wild-Storm/Issue-9\n",
      "Now scraping: The-Wild-Storm/Issue-10\n",
      "Now scraping: The-Wild-Storm/Issue-11\n",
      "Now scraping: The-Wild-Storm/Issue-12\n",
      "Now scraping: The-Wild-Storm/Issue-13\n",
      "Now scraping: The-Wild-Storm/Issue-14\n",
      "Now scraping: The-Wild-Storm/Issue-15\n",
      "Now scraping: The-Wild-Storm/Issue-16\n",
      "Now scraping: The-Wild-Storm/Issue-17\n",
      "Now scraping: The-Wild-Storm/Issue-18\n",
      "Now scraping: The-Wild-Storm/Issue-19\n",
      "Now scraping: The-Wild-Storm/Issue-20\n",
      "Now scraping: The-Wild-Storm/Issue-21\n",
      "Now scraping: The-Wild-Storm/Issue-22\n",
      "df loaded\n",
      "Now scraping: The-Wild-Storm/Issue-4\n"
     ]
    }
   ],
   "source": [
    "series_length=22\n",
    "series_title = \"https://readcomiconline.to/Comic/The-Wild-Storm/\"\n",
    "df_wild_storm = scrape_series(series_title, series_length)\n",
    "df_wild_storm.to_csv('comic_comments/the_wild_storm_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "      <th>Message</th>\n",
       "      <th>Author</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>NumReports</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>I agree with what stan lee said regarding this...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td></td>\n",
       "      <td>Guest</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>He literally wrote sparks dood lol sparks was ...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>I've read all the issues so far and am pretty ...</td>\n",
       "      <td>LEGENDOFLEGAIA</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>The-Wild-Storm/Issue-4</td>\n",
       "      <td>WOW... just wow.  I can't get enough of this. ...</td>\n",
       "      <td>disqus_IXFawpGLcU</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Webpage  \\\n",
       "466  The-Wild-Storm/Issue-4   \n",
       "467  The-Wild-Storm/Issue-4   \n",
       "468  The-Wild-Storm/Issue-4   \n",
       "469  The-Wild-Storm/Issue-4   \n",
       "470  The-Wild-Storm/Issue-4   \n",
       "\n",
       "                                               Message             Author  \\\n",
       "466  I agree with what stan lee said regarding this...     LEGENDOFLEGAIA   \n",
       "467                                                                 Guest   \n",
       "468  He literally wrote sparks dood lol sparks was ...     LEGENDOFLEGAIA   \n",
       "469  I've read all the issues so far and am pretty ...     LEGENDOFLEGAIA   \n",
       "470  WOW... just wow.  I can't get enough of this. ...  disqus_IXFawpGLcU   \n",
       "\n",
       "    Likes Dislikes NumReports  \n",
       "466     1        0          0  \n",
       "467     2        0          0  \n",
       "468     0        1          0  \n",
       "469     0        0          0  \n",
       "470     0        0          0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_wild_storm.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0.2.3 \"Batman\" 2016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCRAPE LONGER (BATMAN 2016)\n",
    "series_length = 70\n",
    "series_title = \"https://readcomiconline.to/Comic/Batman-2016/\"\n",
    "df_batman = scrape_series(series_title, series_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SINGLE ISSUE SCRAPING FOR MISSED ISSUE\n",
    "# Batman 2016 Issue 32 is actually \"Batman-2016/Issue-32-2\"\n",
    "\n",
    "url = \"https://readcomiconline.to/Comic/Batman-2016/Issue-32-2\"\n",
    "df_batman = pd.read_csv('comic_comments/batman_2016_comments.csv', index_col='Unnamed: 0', encoding = \"ISO-8859-1\")\n",
    "df_batman = scrape_issue(url, df=df_batman)\n",
    "df_batman.to_csv('comic_comments/batman_2016_comments.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use both Textblob, Vader to analyze the sentiment of each comment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.0 Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nlp_columns(df):\n",
    "    \"\"\"\n",
    "    Updates df - adds NLP columns if it doesn't already have them\n",
    "    Returns None\n",
    "    \"\"\"\n",
    "\n",
    "    if \"Compound\" not in df.columns: # CHECK IF COLUMNS ALREADY EXIST\n",
    "    \n",
    "        # ADD NLP COLUMNS\n",
    "        df['Polarity'] = None\n",
    "        df['Subjectivity'] = None\n",
    "        df['Positive'] = None\n",
    "        df['Negative'] = None\n",
    "        df['Neutral'] = None\n",
    "        df['Compound'] = None\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(csv_file_path):\n",
    "    \"\"\"\n",
    "    Takes in a webscraped csv of comments (comments in \"Message\" column)\n",
    "    Returns an updated df with TextBlob and Vader columns for each comment\n",
    "    Writes the updated df to file\n",
    "    \"\"\"\n",
    "    # LOAD COMMENTS DF\n",
    "    df = pd.read_csv(csv_file_path, index_col='Unnamed: 0', encoding = \"ISO-8859-1\")\n",
    "    \n",
    "    # ADD SENTIMENT COLUMNS\n",
    "    add_nlp_columns(df)\n",
    "    \n",
    "    # Instantiate Vader analyzer\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        comment = TextBlob(str(df['Message'].iloc[i])) # CREATE TextBlob OBJECT\n",
    "\n",
    "        # FILL IN TextBlob COLUMNS\n",
    "        df['Polarity'].iloc[i] = round(comment.sentiment[0], 3)\n",
    "        df['Subjectivity'].iloc[i] = round(comment.sentiment[1], 3)\n",
    "\n",
    "        # FILL IN Vader COLUMNS\n",
    "        comment = str(comment) # Vader TAKES A STRING\n",
    "\n",
    "        pos, neg, neu, compound = analyzer.polarity_scores(comment)['pos'],\\\n",
    "            analyzer.polarity_scores(comment)['neg'], analyzer.polarity_scores(comment)['neu'],\\\n",
    "            analyzer.polarity_scores(comment)['compound']\n",
    "\n",
    "        df['Positive'].iloc[i] = round(pos,3)\n",
    "        df['Negative'].iloc[i] = round(neg,3)    \n",
    "        df['Neutral'].iloc[i] = round(neu,3)\n",
    "        df['Compound'].iloc[i] = round(compound,3)\n",
    "    \n",
    "    # WRITE TO FILE\n",
    "    df.to_csv(csv_file_path)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Sample sentiment analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply sentiment scores to comments for a scraped comic series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Webpage</th>\n",
       "      <th>Message</th>\n",
       "      <th>Author</th>\n",
       "      <th>Likes</th>\n",
       "      <th>Dislikes</th>\n",
       "      <th>NumReports</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Subjectivity</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative</th>\n",
       "      <th>Neutral</th>\n",
       "      <th>Compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Batman-2016/Issue-1</td>\n",
       "      <td>\"Would... would they have -- Mother and Father...</td>\n",
       "      <td>disqus_MNI1UQuqIh</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Batman-2016/Issue-1</td>\n",
       "      <td>dude i almost cried.</td>\n",
       "      <td>GwenpoolLove</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.464</td>\n",
       "      <td>-0.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Batman-2016/Issue-1</td>\n",
       "      <td>I was rolling my eyes at that.</td>\n",
       "      <td>Anette_Halbestunde</td>\n",
       "      <td>13</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Batman-2016/Issue-1</td>\n",
       "      <td>Me too. It's pretty fucking obvious they would...</td>\n",
       "      <td>disqus_h1pDVQqybe</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Batman-2016/Issue-1</td>\n",
       "      <td>Holy shit! This was epic. I love the new B :TA...</td>\n",
       "      <td>aadityaphadnis</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.122</td>\n",
       "      <td>0.564</td>\n",
       "      <td>0.379</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.444</td>\n",
       "      <td>0.624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Webpage                                            Message  \\\n",
       "0  Batman-2016/Issue-1  \"Would... would they have -- Mother and Father...   \n",
       "1  Batman-2016/Issue-1                               dude i almost cried.   \n",
       "2  Batman-2016/Issue-1                     I was rolling my eyes at that.   \n",
       "3  Batman-2016/Issue-1  Me too. It's pretty fucking obvious they would...   \n",
       "4  Batman-2016/Issue-1  Holy shit! This was epic. I love the new B :TA...   \n",
       "\n",
       "               Author  Likes  Dislikes  NumReports Polarity Subjectivity  \\\n",
       "0   disqus_MNI1UQuqIh     78         1           1     0.15        0.711   \n",
       "1        GwenpoolLove     14         0           0        0            0   \n",
       "2  Anette_Halbestunde     13         5           0        0            0   \n",
       "3   disqus_h1pDVQqybe     10         1           0    0.388         0.75   \n",
       "4      aadityaphadnis     24         0           0    0.122        0.564   \n",
       "\n",
       "  Positive Negative Neutral Compound  \n",
       "0    0.167        0   0.833    0.612  \n",
       "1        0    0.536   0.464    -0.32  \n",
       "2        0        0       1        0  \n",
       "3    0.194    0.098   0.708    0.477  \n",
       "4    0.379    0.177   0.444    0.624  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = \"comic_comments/batman_2016_comments.csv\"\n",
    "\n",
    "df_comments = sentiment_analysis(csv_file_path)\n",
    "\n",
    "df_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLOT SENTIMENTS\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
